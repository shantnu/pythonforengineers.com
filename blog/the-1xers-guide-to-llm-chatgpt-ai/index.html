<!DOCTYPE html>
<html lang="en">
<head>

    <title>The 1xers Guide to LLM, ChatGpt &amp; AI</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../../assets/built/screen.css" />

    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">


    <meta property="og:site_name" content="Python for Engineers">
    <meta property="og:type" content="article">
    <meta property="og:title" content="The 1xers Guide to LLM, ChatGpt &amp; AI">
    <meta property="og:description" content="Alt Title: LLM vs ChatGpt vs HuggingFace vs Llama vs Other Fancy AI Terms You may have heard but had no idea what they meant






I struggled to understand what all these AI terms meant: LLMs, Llamas (not the animal from Peru!). Though I had used ChatGpt, I wasn&#x27;t aware">
    <meta property="og:url" content="https://new.pythonforengineers.com/blog/the-1xers-guide-to-llm-chatgpt-ai/">
    <meta property="article:published_time" content="2024-01-11T11:30:24.000Z">
    <meta property="article:modified_time" content="2024-01-11T11:35:19.000Z">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="The 1xers Guide to LLM, ChatGpt &amp; AI">
    <meta name="twitter:description" content="Alt Title: LLM vs ChatGpt vs HuggingFace vs Llama vs Other Fancy AI Terms You may have heard but had no idea what they meant






I struggled to understand what all these AI terms meant: LLMs, Llamas (not the animal from Peru!). Though I had used ChatGpt, I wasn&#x27;t aware">
    <meta name="twitter:url" content="https://new.pythonforengineers.com/blog/the-1xers-guide-to-llm-chatgpt-ai/">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Shantnu Tiwari">

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Python for Engineers",
        "url": "https://new.pythonforengineers.com/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://new.pythonforengineers.com/favicon.ico"
        }
    },
    "author": {
        "@type": "Person",
        "name": "Shantnu Tiwari",
        "image": {
            "@type": "ImageObject",
            "url": "https://new.pythonforengineers.com/content/images/2021/08/shantnu-foto-small-1.jpg"
        },
        "url": "https://new.pythonforengineers.com/author/shantnu/",
        "sameAs": []
    },
    "headline": "The 1xers Guide to LLM, ChatGpt &amp; AI",
    "url": "https://new.pythonforengineers.com/blog/the-1xers-guide-to-llm-chatgpt-ai/",
    "datePublished": "2024-01-11T11:30:24.000Z",
    "dateModified": "2024-01-11T11:35:19.000Z",
    "description": "Alt Title: LLM vs ChatGpt vs HuggingFace vs Llama vs Other Fancy AI Terms You may have heard but had no idea what they meant\n\n\n\n\n\n\nI struggled to understand what all these AI terms meant: LLMs, Llamas (not the animal from Peru!). Though I had used ChatGpt, I wasn&#x27;t aware of all the intricacies. Why did everyone keep linking to HuggingFace, and what was the big deal about Ollama? How is that different from Llama v2?\n\nSince I had some time over the Christmas holidays, I spent some time playing wit",
    "mainEntityOfPage": "https://new.pythonforengineers.com/blog/the-1xers-guide-to-llm-chatgpt-ai/"
}
    </script>

    <meta name="generator" content="Ghost 5.129">
    <link rel="alternate" type="application/rss+xml" title="Python for Engineers" href="../rss/index.html">


    <link href="https://new.pythonforengineers.com/webmentions/receive/" rel="webmention">
    <script defer src="../../public/cards.min.js%3Fv=ddf1563274"></script>
    <link rel="stylesheet" type="text/css" href="../../public/cards.min.css%3Fv=ddf1563274.css">
    <script defer src="../../public/member-attribution.min.js%3Fv=ddf1563274"></script><style>:root {--ghost-accent-color: #FF1A75;}</style>
    <link rel="stylesheet" href="/assets/css/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<link rel="stylesheet" href="/assets/css/prism-toolbar.min.css" />

</head>
<body class="post-template">
<div class="viewport">

    <header id="gh-head" class="gh-head ">
        <nav class="gh-head-inner inner gh-container">

            <div class="gh-head-brand">
                <a class="gh-head-logo" href="../../home/index.html">
                        Python for Engineers
                </a>
                <a class="gh-burger" role="button">
                    <div class="gh-burger-box">
                        <div class="gh-burger-inner"></div>
                    </div>
                </a>
            </div>
            <div class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="../../home/index.html">Home</a></li>
    <li class="nav-about-contact"><a href="../../about/index.html">About/Contact</a></li>
    <li class="nav-books"><a href="../../books.html">Books</a></li>
    <li class="nav-blog"><a href="../../author/Shantnu/index.html">Blog</a></li>
    <li class="nav-search"><a href="index.html#/search">Search</a></li>
</ul>

            </div>

        </nav>
    </header>

    <main>




<article class="article post no-image">

    <header class="article-header gh-canvas">


        <h1 class="article-title">The 1xers Guide to LLM, ChatGpt &amp; AI</h1>


        <div class="article-byline">
            <section class="article-byline-content">
                <ul class="author-list">
                    <li class="author-list-item">
                        <a href="../../author/Shantnu/index.html" class="author-avatar">
                            <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                        </a>
                    </li>
                </ul>
                <div class="article-byline-meta">
                    <h4 class="author-name"><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></h4>
                    <div class="byline-meta-content">
                        <time class="byline-meta-date" datetime="2024-01-11">Jan 11, 2024</time>
                        <span class="byline-reading-time"><span class="bull">&bull;</span> 7 min read</span>
                    </div>
                </div>
            </section>
        </div>

    </header>

    <section class="gh-content gh-canvas">
        <h3 id="alt-title-llm-vs-chatgpt-vs-huggingface-vs-llama-vs-other-fancy-ai-terms-you-may-have-heard-but-had-no-idea-what-they-meant">Alt Title: LLM vs ChatGpt vs HuggingFace vs Llama vs <em>Other Fancy AI Terms You may have heard but had no idea what they meant</em></h3><h3 id=""></h3><p></p><p>I struggled to understand what all these AI terms meant: LLMs, Llamas (not the animal from Peru!). Though I had used ChatGpt, I wasn't aware of all the intricacies. Why did everyone keep linking to HuggingFace, and what was the big deal about Ollama? How is that different from Llama v2?</p><p>Since I had some time over the Christmas holidays, I spent some time playing with these to get what all these terms mean.</p><p>This article is meant for end users (mainly engineers) who like me are confused with how the whole new AI world works. I'll try to explain what the terms mean and how you can get started in AI (or move beyond using the web version of ChatGPT), including how to run LLMs locally (if you don't know what that means, keep reading!). If nothing else, you can appear smart in conversations.</p><figure class="kg-card kg-image-card"><img src="https://i.imgflip.com/8b65if.jpg" class="kg-image" alt="" loading="lazy"></figure><p>The field is moving ultrafast (even when you take into consideration that software moves fast in general). AI companies make traditional software look like steel manufacturers. But if you know the fundamentals, it's easier to keep up to date with what's happening.</p><p>In this post, I will go over what  LLMs are, and how to run them locally.</p><h3 id="what-is-a-llm-large-language-model">What is a LLM (Large Language Model)</h3><p>The core of ChatGpt etc is a LLM, which is a computer program that can understand, interpret, generate and respond to human languages. The key it can not only understand and interpret, but it can respond in a somewhat intelligent way, and can even generate text (like when you ask it to write a computer program).</p><p>The best explanation of how LLMs work is this one by Stephen Wolfram <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/?ref=new.pythonforengineers.com">https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/</a></p><p></p><p>I will try to summarise it here:</p><p>Remember Google tries to "guess" what you are searching for:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/image.png" class="kg-image" alt="" loading="lazy" width="1668" height="998" srcset="../../content/images/size/w600/2024/01/image.png 600w, ../../content/images/size/w1000/2024/01/image.png 1000w, ../../content/images/size/w1600/2024/01/image.png 1600w, ../../content/images/2024/01/image.png 1668w" sizes="(min-width: 720px) 720px"></figure><p>What sort of a heathen on Google drinks tea without milk?</p><p>A LLM is like a supercharged version of Google's autocomplete. It can not only "guess" the next words, but reply/generate text in a way that sounds intelligent.</p><p>How? Because these LLMs have been trained on Terrabytes and terabytes of data. For example, one LLM <em>Mistral-7B-Instruct  </em>has 7 billion parameters (that's what the 7b stands for). So every time you chat to a 7B model, that's how many parameters it uses to answer your question (which is why a 7B model needs at least 8GB RAM).</p><p>And that is the simplest model. More complex models use more. As of writing this, Meta's LLama2 has 70 billion parameters. Don't know how much RAM I need for that!</p><h3 id="commercial-llms">Commercial LLMs</h3><p></p><p>There are a few commercial LLMs, though I haven't used many. Claude 2 got some publicity at one time though it seems to have gone quiet. Google had their famous "live" "demo" <a href="https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/?ref=new.pythonforengineers.com" rel="noreferrer">which was found to be faked</a>.</p><p>ChatGPT is the best GPT out there (as of writing, remember how fast the field moves).</p><p>ChatGpt 4 is the most advanced version yet. It gives complex and detailed answers. Note, that this version is only available to paid users, so if you are a free user, you can only use 3.5</p><p>ChatGPT 3.5 is good enough for most cases and I prefer it for programming questions, as ChatGpt 4 has a 20 questions every 3 hours limit (and I find it just freezes after that).</p><p>But have no doubts, ChatGPT 4 is really good and miles ahead of the competition. If you are writing an essay, ChatGPT4 really shines. I found this when I was doing research for my blog on Toxic positivity (this is my other blog, focussed <a href="https://shant.nu/toxic-positivity-or-why-happiness-isnt-always-a-good-thing/?ref=new.pythonforengineers.com" rel="noreferrer">mainly on meditation</a>), and couldn't figure out how toxic positivity was different from healthy optimism. I read the top 2 pages of Google results, and I looked at dozens of Reddit/Twitter posts, but I couldn't find a satisfactory answer to my question.</p><p>Until I asked ChatGpt v4, and it gave me the best answer– much better than any blog or article I'd read. <a href="https://shant.nu/toxic-positivity-or-why-happiness-isnt-always-a-good-thing/?ref=new.pythonforengineers.com" rel="noreferrer">If you are interested in this topic, click here </a>to read more.</p><h3 id="open-source-llms">Open Source LLMs</h3><p></p><p>For a long time, ChatGPT and other commercial LLMs were all there were. But in the last year, open source LLMs are catching up.</p><p>There are many places to see which LLM is the best, but <a href="https://huggingface.co/?ref=new.pythonforengineers.com" rel="noreferrer">HuggingFace</a> has a list of all the top ones. Not all of them are open source, but a large majority are.</p><p>There are a few free LLMs that generated big hype. Chief amongst them was <a href="https://ai.meta.com/llama/?ref=new.pythonforengineers.com" rel="noreferrer">LLama 2 </a>from Facebook (no I'm not calling them Meta). More so since the latest version can be used for free even for commercial tools (within limits, but the limits are very generous).</p><p>So which model should you use? If you are just playing around, choose one of the most popular ones. These will be the default values when you run a LLM locally (see below).</p><p>Now the most important thing: How do you run these models locally on your machine?</p><h3 id="running-llms-locally-on-your-own-machine">Running LLMs locally on your own machine</h3><p></p><p>HugginFace has a way to run the models locally but I found it overly complicated. It's geared more towards AI researchers.</p><p></p><p>If you just want to play around (and I suggest you do! You might not need a ChatGPT subscription if the models keep improving), there are 2 easy ways:</p><p></p><p><strong>1 Ollama</strong> <a href="https://ollama.ai/?ref=new.pythonforengineers.com">https://ollama.ai/</a> Though currently only for Mac and Linux, on Windows you can run it via WSL</p><p>I found Ollama the easiest to run– you literally download one file and you can run a Local LLM (Llama 2 is the default one).</p><p>Of course, you need a beefy machine– my Mac is 4 years old and has 8GB RAM (the minimum required), but of course, I have programs running, so I don't get the full 8GB. Which is fine– the LLM is just a little slow. But fine for playing with.</p><p>Here I asked it to generate some Python code:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/CleanShot-2024-01-10-at-12.18.45@2x.png" class="kg-image" alt="" loading="lazy" width="1548" height="1380" srcset="../../content/images/size/w600/2024/01/CleanShot-2024-01-10-at-12.18.45@2x.png 600w, ../../content/images/size/w1000/2024/01/CleanShot-2024-01-10-at-12.18.45@2x.png 1000w, ../../content/images/2024/01/CleanShot-2024-01-10-at-12.18.45@2x.png 1548w" sizes="(min-width: 720px) 720px"></figure><p>This took 10+ minutes to generate, but my laptop is 4+ years old and these beasts use a lot of CPU/RAM.</p><p>There is <a href="https://github.com/ollama-webui/ollama-webui?ref=new.pythonforengineers.com" rel="noreferrer">also a web UI </a>that makes it more like ChatGPT, where you can ask your questions in a web UI. The web UI also makes it easy to add new LLM models. Not only that, but there is also a Hub where you can <a href="https://ollamahub.com/?ref=new.pythonforengineers.com" rel="noreferrer">download multiple models.</a></p><p>I downloaded a model called ScriptKitty, that answers your programming questions like a cat! I've highlighted the puns below:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/CleanShot-2024-01-11-at-09.44.32@2x.png" class="kg-image" alt="" loading="lazy" width="2000" height="1216" srcset="../../content/images/size/w600/2024/01/CleanShot-2024-01-11-at-09.44.32@2x.png 600w, ../../content/images/size/w1000/2024/01/CleanShot-2024-01-11-at-09.44.32@2x.png 1000w, ../../content/images/size/w1600/2024/01/CleanShot-2024-01-11-at-09.44.32@2x.png 1600w, ../../content/images/2024/01/CleanShot-2024-01-11-at-09.44.32@2x.png 2332w" sizes="(min-width: 720px) 720px"></figure><p></p><p>That's purrty good!</p><p><strong>2 Mozilla's LLamafile</strong></p><p><a href="https://github.com/mozilla-Ocho/llamafile?ref=new.pythonforengineers.com" rel="noreferrer">LLamafile</a> from Mozilla is another way to run LLMs locally easily. They have created executables for each model, so you just download the executable you want and run it. And it comes with a handy web UI:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/CleanShot-2024-01-10-at-13.07.52@2x.png" class="kg-image" alt="" loading="lazy" width="1814" height="1404" srcset="../../content/images/size/w600/2024/01/CleanShot-2024-01-10-at-13.07.52@2x.png 600w, ../../content/images/size/w1000/2024/01/CleanShot-2024-01-10-at-13.07.52@2x.png 1000w, ../../content/images/size/w1600/2024/01/CleanShot-2024-01-10-at-13.07.52@2x.png 1600w, ../../content/images/2024/01/CleanShot-2024-01-10-at-13.07.52@2x.png 1814w" sizes="(min-width: 720px) 720px"></figure><p></p><p>The default model they recommend is Llava, which comes with image recognition. I tried it:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/CleanShot-2024-01-10-at-13.41.49@2x.png" class="kg-image" alt="" loading="lazy" width="1708" height="1104" srcset="../../content/images/size/w600/2024/01/CleanShot-2024-01-10-at-13.41.49@2x.png 600w, ../../content/images/size/w1000/2024/01/CleanShot-2024-01-10-at-13.41.49@2x.png 1000w, ../../content/images/size/w1600/2024/01/CleanShot-2024-01-10-at-13.41.49@2x.png 1600w, ../../content/images/2024/01/CleanShot-2024-01-10-at-13.41.49@2x.png 1708w" sizes="(min-width: 720px) 720px"></figure><p>It got the basics right and hallucinated some stuff. I think the model was confused by unrelated stuff in the background.</p><h3 id="using-ai-to-create-images">Using AI to create images</h3><p></p><p>So far I've only talked about using LLM for text(which includes code). But you can also use it for images.</p><p>There are a few tools– Dall-E from OpenAI, Midjourney, and something from Adobe(whose name I've already forgotten).</p><p>I've only used DallE, as it is included in the  ChatGPT subscription. As an example, I gave it this instruction:</p><blockquote>generate an image: A girl in a cyber punk neo noir world fighting super smart robots. She is in a city like that from Blade runner, with lots of people and large holographic ads</blockquote><p>I got:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/cyberpunk-girl.webp" class="kg-image" alt="" loading="lazy" width="1024" height="1024" srcset="../../content/images/size/w600/2024/01/cyberpunk-girl.webp 600w, ../../content/images/size/w1000/2024/01/cyberpunk-girl.webp 1000w, ../../content/images/2024/01/cyberpunk-girl.webp 1024w" sizes="(min-width: 720px) 720px"></figure><p></p><p>I asked to create an 8bit, retro video game style version of the above:</p><figure class="kg-card kg-image-card"><img src="../../content/images/2024/01/cyberpunk-girl-8bit.webp" class="kg-image" alt="" loading="lazy" width="1024" height="1024" srcset="../../content/images/size/w600/2024/01/cyberpunk-girl-8bit.webp 600w, ../../content/images/size/w1000/2024/01/cyberpunk-girl-8bit.webp 1000w, ../../content/images/2024/01/cyberpunk-girl-8bit.webp 1024w" sizes="(min-width: 720px) 720px"></figure><p></p><p><strong>Legal stuff: </strong>While text based LLMs have had some controversy that their text is stealing copyrighted material, image generators are much worse as they have been found to outright copy other artists. So be careful and don't use any AI generated images in any commercial project, unless the tool guarantees there are no copyright infringements. So far, only Adobe offers this guarantee.</p><p>While this is also true of text, at least when it comes to programming, there are only so many ways you can write a for loop. But in artistic things like images, it is very easy to see the AI just copied someone's image and changed the shirt from green to blue. So just be careful.</p><h3 id="great-blogs-to-follow">Great blogs to follow:</h3><p></p><p>Following these blogs will make you go from 0.1x to 1x!</p><p>Ethan Mollick: <a href="https://www.oneusefulthing.org/?ref=new.pythonforengineers.com">https://www.oneusefulthing.org/</a></p><p>Simon Williamson: <a href="https://simonw.substack.com/?ref=new.pythonforengineers.com">https://simonw.substack.com/</a></p><p><strong>That's it, folks!</strong></p><p>I will keep adding new stuff (or writing new posts) as I learn more. I have more stuff I want to learn, like how to call these LLM models from a Python script. While there are a few tools, I'm not sure which one is the best to use. I will come back to this.</p><p>I also want to look at AI video generation.</p><p>Sign up for my email list to know when the next post in this series is out.</p>
    </section>


</article>



<aside class="read-more-wrap">
    <div class="read-more inner">



<article class="post-card post no-image ">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../awesome-python-library-tenacity/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">Awesome Python Library: Tenacity</h2>
            </header>
            <section class="post-card-excerpt">
                <p>Link: https://tenacity.readthedocs.io/en/latest/

When writing code or tests in Python, one issue I had was when the code would fail due to random things like network issues or external peripherals not responding in time. Just rerunning the tests would make them pass. The unreliability wasn&#39;</p>
            </section>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../../author/Shantnu/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></span>
                <span class="post-card-byline-date"><time datetime="2024-04-10">Apr 10, 2024</time> <span class="bull">&bull;</span> 2 min read</span>
            </div>
        </footer>

    </div>

</article>

<article class="post-card post no-image ">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../so-evidently/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">So Google&#x27;s Gemini Doesn&#x27;t Like Python Programming and Sanskrit?</h2>
            </header>
            <section class="post-card-excerpt">
                <p>I have been playing around with Googles Gemini Pro.

Recently, I wanted to write a blog on Python&#39;s decorators and wanted to get some ideas for practical projects I could build with them. Tried GPT4 first, it gave me the standard &quot;log analyser&quot; that all blogs</p>
            </section>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../../author/Shantnu/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></span>
                <span class="post-card-byline-date"><time datetime="2024-02-25">Feb 25, 2024</time> <span class="bull">&bull;</span> 4 min read</span>
            </div>
        </footer>

    </div>

</article>

<article class="post-card post ">

    <a class="post-card-image-link" href="../linkedin-has-become-a-piece-of-garbage-even-more-than-usual/index.html">
        <img class="post-card-image"
            srcset="../../content/images/size/w300/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.png 300w,
                   ../../content/images/size/w600/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.pngg 600w,
                  ../../content/images/size/w1000/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.pngng 1000w,
                 ../../content/images/size/w2000/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.pngpng 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="../../content/images/size/w600/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.png"
            alt="LinkedIn Has Become a Pile of Garbage (even more than usual)"
            loading="lazy"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../linkedin-has-become-a-piece-of-garbage-even-more-than-usual/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">LinkedIn Has Become a Pile of Garbage (even more than usual)</h2>
            </header>
            <section class="post-card-excerpt">
                <p>Online forums, especially Hacker News and Reddit, are very hostile to LinkedIn. Everyone makes fun of the self-promotion and silliness that goes there. There are complaints the site is unusable, which I didn&#39;t agree with until now.

I&#39;ve had an account there for a few years.</p>
            </section>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../../author/Shantnu/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></span>
                <span class="post-card-byline-date"><time datetime="2024-01-29">Jan 29, 2024</time> <span class="bull">&bull;</span> 4 min read</span>
            </div>
        </footer>

    </div>

</article>

    </div>
</aside>


    </main>

    <footer class="site-footer outer">
        <div class="inner">
            <section class="copyright"><a href="../../home/index.html">Python for Engineers</a> &copy; 2025</section>
            <nav class="site-footer-nav">

            </nav>


        </div>
    </footer>

</div>


<script
    src="/assets/js/jquery-3.5.1.min.js"
    integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous">
</script>
<script src="../../assets/built/casper.js"></script>
<script>
$(document).ready(function () {
    // Mobile Menu Trigger
    $('.gh-burger').click(function () {
        $('body').toggleClass('gh-head-open');
    });
    // FitVids - Makes video embeds responsive
    $(".gh-content").fitVids();
});
</script>

<script src="/assets/js/prism.min.js" integrity="sha512-axJX7DJduStuBB8ePC8ryGzacZPr3rdLaIDZitiEgWWk2gsXxEFlm4UW0iNzj2h3wp5mOylgHAzBzM4nRSvTZA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>



<script src="/assets/js/prism-toolbar.min.js" integrity="sha512-YrvgEHAi5/3o2OT+/vh1z19oJXk/Kk0qdVKbjEFl9VRmcLTaWRYzVziZCvoGpJ2TrnV7rB8pnJcz1ioVJjgw2A==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

</body>
</html>
