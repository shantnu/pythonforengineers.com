<!DOCTYPE html>
<html lang="en">
<head>

    <title>Build a Spam Filter</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../../assets/built/screen.css" />

    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    
    <meta property="og:site_name" content="Python for Engineers">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Build a Spam Filter">
    <meta property="og:description" content="0. Introduction to NLP and Sentiment Analysis
[https://new.pythonforengineers.com/blog/natural-language-processing-and-sentiment-analysis-with-python/]

1. Natural Language Processing with NTLK
[https://new.pythonforengineers.com/blog/introduction-to-nltk-natural-language-processing-with-python/]

2. Intro to NTLK, Part 2
[https://new.pythonforengineers.com/blog/intro-to-nltk-part-2/]

3. Build a sentiment analysis program
[https://new.pythonforengineers.com/blog/build-a-sentiment-analysis-app-w">
    <meta property="og:url" content="https://new.pythonforengineers.com/blog/build-a-spam-filter/">
    <meta property="article:published_time" content="2021-08-18T13:14:50.000Z">
    <meta property="article:modified_time" content="2021-08-18T13:14:50.000Z">
    <meta property="article:tag" content="nltk">
    <meta property="article:tag" content="machine-learning">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Build a Spam Filter">
    <meta name="twitter:description" content="0. Introduction to NLP and Sentiment Analysis
[https://new.pythonforengineers.com/blog/natural-language-processing-and-sentiment-analysis-with-python/]

1. Natural Language Processing with NTLK
[https://new.pythonforengineers.com/blog/introduction-to-nltk-natural-language-processing-with-python/]

2. Intro to NTLK, Part 2
[https://new.pythonforengineers.com/blog/intro-to-nltk-part-2/]

3. Build a sentiment analysis program
[https://new.pythonforengineers.com/blog/build-a-sentiment-analysis-app-w">
    <meta name="twitter:url" content="https://new.pythonforengineers.com/blog/build-a-spam-filter/">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Shantnu Tiwari">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="nltk, machine-learning">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Python for Engineers",
        "url": "https://new.pythonforengineers.com/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://new.pythonforengineers.com/favicon.ico"
        }
    },
    "author": {
        "@type": "Person",
        "name": "Shantnu Tiwari",
        "image": {
            "@type": "ImageObject",
            "url": "https://new.pythonforengineers.com/content/images/2021/08/shantnu-foto-small-1.jpg"
        },
        "url": "https://new.pythonforengineers.com/author/shantnu/",
        "sameAs": []
    },
    "headline": "Build a Spam Filter",
    "url": "https://new.pythonforengineers.com/blog/build-a-spam-filter/",
    "datePublished": "2021-08-18T13:14:50.000Z",
    "dateModified": "2021-08-18T13:14:50.000Z",
    "keywords": "nltk, machine-learning",
    "description": "0. Introduction to NLP and Sentiment Analysis\n[https://new.pythonforengineers.com/blog/natural-language-processing-and-sentiment-analysis-with-python/]\n\n1. Natural Language Processing with NTLK\n[https://new.pythonforengineers.com/blog/introduction-to-nltk-natural-language-processing-with-python/]\n\n2. Intro to NTLK, Part 2\n[https://new.pythonforengineers.com/blog/intro-to-nltk-part-2/]\n\n3. Build a sentiment analysis program\n[https://new.pythonforengineers.com/blog/build-a-sentiment-analysis-app-w",
    "mainEntityOfPage": "https://new.pythonforengineers.com/blog/build-a-spam-filter/"
}
    </script>

    <meta name="generator" content="Ghost 5.129">
    <link rel="alternate" type="application/rss+xml" title="Python for Engineers" href="../rss/index.html">
        
    
    <link href="https://new.pythonforengineers.com/webmentions/receive/" rel="webmention">
    <script defer src="../../public/cards.min.js%3Fv=ddf1563274"></script>
    <link rel="stylesheet" type="text/css" href="../../public/cards.min.css%3Fv=ddf1563274.css">
    <script defer src="../../public/member-attribution.min.js%3Fv=ddf1563274"></script><style>:root {--ghost-accent-color: #FF1A75;}</style>
    <link rel="stylesheet" href="/assets/css/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<link rel="stylesheet" href="/assets/css/prism-toolbar.min.css" />

</head>
<body class="post-template tag-nltk tag-machine-learning">
<div class="viewport">

    <header id="gh-head" class="gh-head ">
        <nav class="gh-head-inner inner gh-container">

            <div class="gh-head-brand">
                <a class="gh-head-logo" href="../../home/index.html">
                        Python for Engineers
                </a>
                <a class="gh-burger" role="button">
                    <div class="gh-burger-box">
                        <div class="gh-burger-inner"></div>
                    </div>
                </a>
            </div>
            <div class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="../../home/index.html">Home</a></li>
    <li class="nav-about-contact"><a href="../../about/index.html">About/Contact</a></li>
    <li class="nav-books"><a href="../../books.html">Books</a></li>
    <li class="nav-blog"><a href="../../author/Shantnu/index.html">Blog</a></li>
    <li class="nav-search"><a href="index.html#/search">Search</a></li>
</ul>

            </div>
            <div class="gh-head-actions">
                <div class="gh-social">
                </div>

                    <a class="gh-head-button" href="index.html#/portal/signup">Subscribe</a>
            </div>
        </nav>
    </header>

    <main>
        



<article class="article post tag-nltk tag-machine-learning no-image">

    <header class="article-header gh-canvas">

        <section class="article-tag">
            <a href="../../tag/nltk/index.html">nltk</a>
        </section>

        <h1 class="article-title">Build a Spam Filter</h1>


        <div class="article-byline">
            <section class="article-byline-content">
                <ul class="author-list">
                    <li class="author-list-item">
                        <a href="../../author/Shantnu/index.html" class="author-avatar">
                            <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                        </a>
                    </li>
                </ul>
                <div class="article-byline-meta">
                    <h4 class="author-name"><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></h4>
                    <div class="byline-meta-content">
                        <time class="byline-meta-date" datetime="2021-08-18">Aug 18, 2021</time>
                        <span class="byline-reading-time"><span class="bull">&bull;</span> 10 min read</span>
                    </div>
                </div>
            </section>
        </div>

    </header>

    <section class="gh-content gh-canvas">
        <p><a href="../natural-language-processing-and-sentiment-analysis-with-python/index.html"><strong>0. Introduction to NLP and Sentiment Analysis</strong></a></p><p><strong><a href="../introduction-to-nltk-natural-language-processing-with-python/index.html">1. Natural Language Processing with NTLK</a></strong></p><p><strong><a href="../intro-to-nltk-part-2/index.html">2. Intro to NTLK, Part 2</a></strong></p><p><a href="../build-a-sentiment-analysis-app-with-movie-reviews/index.html"><strong>3. Build a sentiment analysis program</strong></a></p><p><strong><a href="../practice-session-sentiment-analysis-with-twitter/index.html">4. Sentiment Analysis with Twitter</a></strong></p><p><strong><a href="../analysing-the-enron-email-corpus/index.html">5. Analysing the Enron Email Corpus</a></strong></p><p><a href="index.html"><strong>6. Build a Spam Filter using the Enron Corpus</strong></a></p><hr><p><br><em>In this lesson, we will try to build a spam filter using the Enron email dataset, using everything we learnt so far</em></p><!--kg-card-begin: markdown--><p>So this is the first guided practice session I’m trying. The aim is, I’ll give you hints on how to complete the lessons, same as I give in practice sessions. But I’ll also give you the solution in the next video.</p>
<p>You can only look at the solution videos if you want, but I recommend trying to solve the problem yourself first. If you have completed all the pre-requisites, the challenges should be easy.</p>
<p>The repo is <a href="https://github.com/shantnu/Enron-Spam?ref=new.pythonforengineers.com">here</a>. <em>Enron Spam Practice.ipynb</em> is the file you will be working in, while <em>Enron Spam Solution.ipynb</em> contains the solutions.</p>
<h2 id="challenge-1-print-all-the-directories-and-files">Challenge 1: Print all the directories and files</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804607?app_id=122963&amp;h=432aa23196" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 1"></iframe></figure><!--kg-card-begin: markdown--><p>The first video introduces the Enron Spam dataset. Get it from here: <a href="https://www.aueb.gr/users/ion/data/enron-spam/?ref=new.pythonforengineers.com">https://www.aueb.gr/users/ion/data/enron-spam/</a></p>
<p>Extract all into a folder called <em>Enron Spam</em>. You will need 7zip if you are on Windows. Spend some time studying how the emails are laid out. All the spam emails are in a folder called <em>spam</em>, while non-spam are in <em>ham</em>.</p>
<p>The first challenge is simply to print all the directories, sub directories and files in the folder. This should be quite simple, as it’s the first thing we did in the Enron example.</p>
<h2 id="solution-1">Solution 1</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804596?app_id=122963&amp;h=8eba80a0e1" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 2"></iframe></figure><!--kg-card-begin: markdown--><p>The solution is quite simple.</p>
<pre><code class="language-python">rootdir = &quot;C:\\Users\\Shantnu\\Desktop\\Data Sources\\Enron Spam&quot;

for directories, subdirs, files in os.walk(rootdir):
    print(directories, subdirs, len(files))

C:\Users\Shantnu\Desktop\Data Sources\Enron Spam ['enron1', 'enron2', 'enron3', 'enron4', 'enron5', 'enron6'] 0
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron1 ['ham', 'spam'] 1
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron1\ham [] 3672
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron1\spam [] 1500
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron2 ['ham', 'spam'] 1

..... snipped ....
</code></pre>
<h2 id="challenge-2-print-only-files-in-the-ham-and-spam-folder">Challenge 2 Print only files in the Ham and Spam folder</h2>
<p>The video for this has been mixed with the last solutions video (from 3:55 onwards).</p>
<p>The challenge is: Instead of printing all files and folders, only print the files when we are in the <em>ham</em> or <em>spam</em> folder.</p>
<p>I give you a hint. The <em>os.path.split()</em> can be used to find out which directory you are in. Like so:</p>
<pre><code class="language-python">print(os.path.split(&quot;C:\\Users\\Shantnu\\Desktop\\Data Sources\\Enron Spam\\enron1\\ham&quot;))
print(os.path.split(&quot;C:\\Users\\Shantnu\\Desktop\\Data Sources\\Enron Spam\\enron1\\ham&quot;)[0])
print(os.path.split(&quot;C:\\Users\\Shantnu\\Desktop\\Data Sources\\Enron Spam\\enron1\\ham&quot;)[1])

('C:\\Users\\Shantnu\\Desktop\\Data Sources\\Enron Spam\\enron1', 'ham')
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron1
ham
</code></pre>
<p>The third example above shows you how to detect you are in the <em>ham</em> folder.</p>
<h2 id="solution-2">Solution 2</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804595?app_id=122963&amp;h=1ec53812b8" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 3"></iframe></figure><!--kg-card-begin: markdown--><p>We take the code we had before and modify it, so that we are checking if we are in the <em>ham</em> or <em>spam</em> folder.</p>
<pre><code class="language-python"># Same as before, but only print the ham and spam folders
for directories, subdirs, files in os.walk(rootdir):
    if (os.path.split(directories)[1]  == 'ham'):
        print(directories, subdirs, len(files))

    if (os.path.split(directories)[1]  == 'spam'):
        print(directories, subdirs, len(files))

directories, subdirs, len(files))

C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron1\ham [] 3672
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron1\spam [] 1500
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron2\ham [] 4361
C:\Users\Shantnu\Desktop\Data Sources\Enron Spam\enron2\spam [] 1496

... snipped ...
</code></pre>
<p>The key part is this:</p>
<pre><code class="language-python"> if (os.path.split(directories)[1]  == 'ham'):
        print(directories, subdirs, len(files))
</code></pre>
<p>This is where we are checking if we are in the right folder.</p>
<p>Why does it matter?</p>
<p>Because when we start reading the files, we want to make sure we are only reading them from the <em>spam</em> and <em>ham</em> folders.</p>
<h2 id="challenge-3-read-all-the-files-in-the-ham-and-spam-folders">Challenge 3: Read all the files in the Ham and Spam folders</h2>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Now that you can print the files in the spam and ham folders, it’s time to go ahead and read all the files in those folders.</p>
<p>I’ve given you some code to start off:</p>
<pre><code class="language-python">ham_list = []
spam_list = []

# Same as before, but this time, read the files, and append them to the ham and spam list

# You WILL get a Unicode error for the spam part- either Google it, or look at my solution

print(ham_list[0])
print(spam_list[0])
</code></pre>
<p>There is a ham_list and spam_list, and you have to store the content of the files in these lists.</p>
<p>I give you a warning: The spam files <strong>will</strong> throw you a <em>Unicode</em> error when you try to read them. You can either Google for the solution, or look at mine. A hint is: It’s a unicode problem (duh) which will only be seen on Python 3, not 2.</p>
<p>But I still recommend you give the challenge a try. Feel free to comment out the <em>spam</em> part of the code, as the two parts are similar anyway.</p>
<h2 id="solution-3">Solution 3</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804602?app_id=122963&amp;h=52cac8e694" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 5"></iframe></figure><!--kg-card-begin: markdown--><p>Let’s look at the code in parts. First, the code to read the ham files:</p>
<pre><code class="language-python">for directories, subdirs, files in os.walk(rootdir):
    if (os.path.split(directories)[1]  == 'ham'):
        for filename in files:
            with open(os.path.join(directories, filename)) as f:
                data = f.read()
                ham_list.append(data)
</code></pre>
<p>It’s the same as before, except this part is new:</p>
<pre><code class="language-python">        for filename in files:
            with open(os.path.join(directories, filename)) as f:
                data = f.read()
                ham_list.append(data)
</code></pre>
<p>We loop over all the files, open each, read the text and append it to the ham_list. And we do the same for the spam list.</p>
<pre><code class="language-python">    if (os.path.split(directories)[1]  == 'spam'):
        for filename in files:
            with open(os.path.join(directories, filename)) as f:
                data = f.read()
                spam_list.append(data)
</code></pre>
<p>Run the code, and you will see the Unicode error. Why is that?</p>
<p>By putting in some extra debug, I found a few of the files throwing errors. One is the <em>2248.2004-09-23.GP.spam.txt</em> in the Enron1/spam folder. Open this in a text editor:</p>
<p><img src="../../content/images/2021/08/enronspam1.png" alt="enronspam1" loading="lazy"></p>
<p>You will note the file has special characters in it. This means it’s not a pure text (which is not that surprising, as it is spam).</p>
<p>Python 2 would allow you to get away with this. Python 3 won’t.</p>
<p>The way around this is to specify the encoding. Here’s a page with some details: <a href="https://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html?ref=new.pythonforengineers.com">https://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html</a></p>
<p>The link explains the unicode error you get. It also tells you you have to specify the encoding. There are several options, but the simplest one is <em>latin-1</em>. This is closest to what Python 2 did.</p>
<p>The <em>latin-1</em> encoding means Python will try its best to decode the text without throwing an error. The downside is, the data might be corrupted. However, this is spam, so we expect bad data. Also, we’ll have millions of words in the spam list, and even if 1-2 are corrupt, we can live with that.</p>
<p>So the way to stop Python throwing an error is to change this line to add an encoding:</p>
<pre><code class="language-python">with open(os.path.join(directories, filename), encoding=&quot;latin-1&quot;) as f:
</code></pre>
<p>The code now works.</p>
<h2 id="challenge-4-prepare-our-data-for-the-naive-bayes-filter">Challenge 4 Prepare our data for the Naive Bayes filter</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804598?app_id=122963&amp;h=1d11a3ef9d" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 6"></iframe></figure><!--kg-card-begin: markdown--><p>We will be using the Naive Bayes for our spam filter. If you have done the Nltk lessons, you know it expects the input in a particular format. That’s the goal of this challenge. I give you a few hints:</p>
<pre><code class="language-python"># Write a function , that when passed in words, will return a dictionary of the form

# {Word1: True, Word2: True, Words3: True}

# Removing stop words is optional

def create_word_features(words):
    pass
</code></pre>
<p>So the first thing is to write a <em>create_word_features()</em> function. The second is to use this (with word tokenize):</p>
<pre><code class="language-python">ham_list = []
spam_list = []

# Same as before, but this time:

# 1. Break the sentences into words using word_tokenize
# 2. Use the create_word_features() function you just wrote

print(ham_list[0])
print(spam_list[0])
</code></pre>
<h2 id="solution-4">Solution 4</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804743?app_id=122963&amp;h=3e3de72182" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 7"></iframe></figure><!--kg-card-begin: markdown--><p>Since this stuff has been covered in the Ntlk tutorial, I will zip through it a bit.</p>
<p>First, the <em>create_word_features()</em> function:</p>
<pre><code class="language-python">def create_word_features(words):
    my_dict = dict( [ (word, True) for word in words] )
    return my_dict

create_word_features([&quot;the&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;quick&quot;, &quot;a&quot;, &quot;fox&quot;])

{'a': True, 'brown': True, 'fox': True, 'quick': True, 'the': True}
</code></pre>
<p>We are just creating a dictionary that returns True for each word. I’m not removing stop words for this example.</p>
<p>Next, we use our function. I’m going to be working with the code from the previous example. This is what we did last time:</p>
<pre><code class="language-python">for directories, subdirs, files in os.walk(rootdir):
    if (os.path.split(directories)[1]  == 'ham'):
        for filename in files:
            with open(os.path.join(directories, filename)) as f:
                data = f.read()
                ham_list.append(data)
</code></pre>
<p>We were reading the data and appending it to ham_list. This will now change to:</p>
<pre><code class="language-python">with open(os.path.join(directories, filename), encoding=&quot;latin-1&quot;) as f:
                data = f.read()

                # The data we read is one big string. We need to break it into words.
                words = word_tokenize(data)

                ham_list.append((create_word_features(words), &quot;ham&quot;))
</code></pre>
<p>So we break the text into words with:</p>
<pre><code class="language-python"># The data we read is one big string. We need to break it into words.
                words = word_tokenize(data)
</code></pre>
<p>And then we call the function we wrote:</p>
<pre><code class="language-python"> ham_list.append((create_word_features(words), &quot;ham&quot;))
</code></pre>
<p>We are appending a <em>“ham”</em> at the end. This is to tell the machine learning algorithm that this text is of type <em>ham</em>. The actual word doesn’t matter, as long as it’s consistent.</p>
<p>We will do the same for the spam list, so the final code looks like:</p>
<pre><code class="language-python">ham_list = []
spam_list = []

# Same as before, but this time:

# 1. Break the sentences into words using word_tokenize
# 2. Use the create_word_features() function you just wrote
for directories, subdirs, files in os.walk(rootdir):
    if (os.path.split(directories)[1]  == 'ham'):
        for filename in files:
            with open(os.path.join(directories, filename), encoding=&quot;latin-1&quot;) as f:
                data = f.read()

                # The data we read is one big string. We need to break it into words.
                words = word_tokenize(data)

                ham_list.append((create_word_features(words), &quot;ham&quot;))

    if (os.path.split(directories)[1]  == 'spam'):
        for filename in files:
            with open(os.path.join(directories, filename), encoding=&quot;latin-1&quot;) as f:
                data = f.read()

                # The data we read is one big string. We need to break it into words.
                words = word_tokenize(data)

                spam_list.append((create_word_features(words), &quot;spam&quot;))
print(ham_list[0])
print(spam_list[0])
</code></pre>
<p>This looks fairly complex, but since we built it in parts, it should be easy to follow.</p>
<h2 id="challenge-5-create-the-testtrain-data-call-the-naive-bayes-filter">Challenge 5 Create the Test/Train data, call the Naive Bayes Filter</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804599?app_id=122963&amp;h=a77f6a191e" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 8"></iframe></figure><!--kg-card-begin: markdown--><p>We are reaching the final steps. The next challenge is to create test / train samples. I give you some code:</p>
<pre><code class="language-python">combined_list = ham_list + spam_list

random.shuffle(combined_list)
</code></pre>
<p>We combine our spam and ham list, and then shuffle it, so that it is randomised.</p>
<p>The first thing you need to do is create test/train splits:</p>
<pre><code class="language-python"># Create a test and train section.

# 70% of the data is training. 30% is test
</code></pre>
<p>And then call the Naive Bayes filter, and find the accuracy:</p>
<pre><code class="language-python"># Create the Naive Bayes filter

# Find the accuracy, using the test data

print(&quot;Accuracy is: &quot;, accuracy * 100)
</code></pre>
<h2 id="solution-5">Solution 5</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804603?app_id=122963&amp;h=46a3e1e569" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 9"></iframe></figure><!--kg-card-begin: markdown--><p>We start by calculating what 70% of the data will be.</p>
<pre><code class="language-python">training_part = int(len(combined_list) * .7)
</code></pre>
<p>I’m converting it to <em>int()</em> so I can get a whole number.</p>
<p>We then divide our samples into test and training sets:</p>
<pre><code class="language-python">print(len(combined_list))

training_set = combined_list[:training_part]

test_set =  combined_list[training_part:]

print (len(training_set))
print (len(test_set))

33716
23601
10115
</code></pre>
<p>We now create the Naive Bayes filter with the training data, and test with test data:</p>
<pre><code class="language-python"># Create the Naive Bayes filter

classifier = NaiveBayesClassifier.train(training_set)

# Find the accuracy, using the test data

accuracy = nltk.classify.util.accuracy(classifier, test_set)

print(&quot;Accuracy is: &quot;, accuracy * 100)

Accuracy is:  98.50716757291151
</code></pre>
<p>We are getting an accuracy of 98%, which is good.</p>
<p>We will also look at the most interesting features:</p>
<pre><code class="language-python">classifier.show_most_informative_features(20)

                  enron = True              ham : spam   =   3588.6 : 1.0
                     hpl = True              ham : spam   =    577.0 : 1.0
                     php = True             spam : ham    =    416.2 : 1.0
                     713 = True              ham : spam   =    326.3 : 1.0
                  louise = True              ham : spam   =    299.2 : 1.0
                     xls = True              ham : spam   =    281.8 : 1.0
                 stinson = True              ham : spam   =    267.4 : 1.0
                crenshaw = True              ham : spam   =    251.5 : 1.0
                     ect = True              ham : spam   =    231.2 : 1.0
                   corel = True             spam : ham    =    220.5 : 1.0
              macromedia = True             spam : ham    =    210.9 : 1.0
              scheduling = True              ham : spam   =    209.6 : 1.0
                        = True              ham : spam   =    184.1 : 1.0
                     sex = True             spam : ham    =    182.3 : 1.0
                      xp = True             spam : ham    =    172.6 : 1.0
                   daren = True              ham : spam   =    168.7 : 1.0
                    1933 = True             spam : ham    =    152.1 : 1.0
                    spam = True             spam : ham    =    145.1 : 1.0
                 parsing = True              ham : spam   =    137.6 : 1.0
                   penis = True             spam : ham    =    117.2 : 1.0
</code></pre>
<p>So the word <em>Enron</em> is more likely to appear in ham emails than spam, while <em>sex</em> is more likely to appear in spam. <em>php</em> also appears a lot in spam, but that maybe a 90s thing (as do corel and macromedia, both expensive software).</p>
<h2 id="challenge-6-identify-messages-as-spam-or-ham">Challenge 6: Identify messages as spam or ham</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804605?app_id=122963&amp;h=da7f5fc05f" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 10"></iframe></figure><!--kg-card-begin: markdown--><p>We have 3 messages we want to classify as spam or ham:</p>
<pre><code class="language-python"># Clasify the below as spam or ham

# Hint: 1. Break into words using word_tokenzise
# 2. create_word_features
# 3. Use the classify function

msg1 = '''Hello th̓ere seُx master :-)
i need c0ck ri͏ght noِw ..͏. don't tell my hǔbbٚy.ٚ. ))
My sc͕rٞeٚe̻nname is Dorry.
My accֺo֔unt is h֯ere: http:nxusxbnd.GirlsBadoo.ru
C u late٘r!'''


msg2 = '''As one of our top customers we are providing 10% OFF the total of your next used book purchase from www.letthestoriesliveon.com. Please use the promotional code, TOPTENOFF at checkout. Limited to 1 use per customer. All books have free shipping within the contiguous 48 United States and there is no minimum purchase.

We have millions of used books in stock that are up to 90% off MRSP and add tens of thousands of new items every day. Don’t forget to check back frequently for new arrivals.'''



msg3 = '''To start off, I have a 6 new videos + transcripts in the members section. In it, we analyse the Enron email dataset, half a million files, spread over 2.5GB. It's about 1.5 hours of  video.

I have also created a Conda environment for running the code (both free and member lessons). This is to ensure everyone is running the same version of libraries, preventing the Works on my machine problems. If you get a second, do you mind trying it here?'''
</code></pre>
<p>The first is clearly spam. The 2nd is also spam, but doesn’t use spam like language. The 3rd is my own email (and should not be classified as spam!)</p>
<p>At the top, I give you a hint about what to do. There are 3 steps: 1) Break into words 2) Create word features 3) Call the <em>classify()</em> function.</p>
<h2 id="solution-6">Solution 6</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><iframe src="https://player.vimeo.com/video/151804606?app_id=122963&amp;h=7c26b5d81c" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Enron Spam 11"></iframe></figure><!--kg-card-begin: markdown--><p>There isn’t a lot to explain in this code:</p>
<pre><code class="language-python">words = word_tokenize(msg1)
features = create_word_features(words)
print(&quot;Message 1 is :&quot; ,classifier.classify(features))

Message 1 is : spam

words = word_tokenize(msg2)
features = create_word_features(words)
print(&quot;Message 2 is :&quot; ,classifier.classify(features))

words = word_tokenize(msg2)

features = create_word_features(words)

print(&quot;Message 2 is :&quot; ,classifier.classify(features))

Message 2 is : spam


words = word_tokenize(msg3)
features = create_word_features(words)
print(&quot;Message 3 is :&quot; ,classifier.classify(features))

Message 3 is : ham
</code></pre>
<p>And there you go. A simple spam filter.</p>
<p>Some final comments: This spam filter was built for spam in the 90s, and the type of spam messages has grown. If you wanted to use this today, you would add a few modern spam messages to the training data, and retrain.</p>
<p>I hope you also appreciated how complex looking code becomes easy if you build it in small parts.</p>
<!--kg-card-end: markdown-->
    </section>


</article>



<aside class="read-more-wrap">
    <div class="read-more inner">


                    
<article class="post-card post no-image ">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../awesome-python-library-tenacity/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">Awesome Python Library: Tenacity</h2>
            </header>
            <section class="post-card-excerpt">
                <p>Link: https://tenacity.readthedocs.io/en/latest/

When writing code or tests in Python, one issue I had was when the code would fail due to random things like network issues or external peripherals not responding in time. Just rerunning the tests would make them pass. The unreliability wasn&#39;</p>
            </section>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../../author/Shantnu/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></span>
                <span class="post-card-byline-date"><time datetime="2024-04-10">Apr 10, 2024</time> <span class="bull">&bull;</span> 2 min read</span>
            </div>
        </footer>

    </div>

</article>
                    
<article class="post-card post no-image ">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../so-evidently/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">So Google&#x27;s Gemini Doesn&#x27;t Like Python Programming and Sanskrit?</h2>
            </header>
            <section class="post-card-excerpt">
                <p>I have been playing around with Googles Gemini Pro.

Recently, I wanted to write a blog on Python&#39;s decorators and wanted to get some ideas for practical projects I could build with them. Tried GPT4 first, it gave me the standard &quot;log analyser&quot; that all blogs</p>
            </section>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../../author/Shantnu/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></span>
                <span class="post-card-byline-date"><time datetime="2024-02-25">Feb 25, 2024</time> <span class="bull">&bull;</span> 4 min read</span>
            </div>
        </footer>

    </div>

</article>
                    
<article class="post-card post ">

    <a class="post-card-image-link" href="../linkedin-has-become-a-piece-of-garbage-even-more-than-usual/index.html">
        <img class="post-card-image"
            srcset="../../content/images/size/w300/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.png 300w,
                   ../../content/images/size/w600/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.pngg 600w,
                  ../../content/images/size/w1000/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.pngng 1000w,
                 ../../content/images/size/w2000/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.pngpng 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="../../content/images/size/w600/2024/01/ae223740-840b-4d4a-9467-2522a67dcbbc.png"
            alt="LinkedIn Has Become a Pile of Garbage (even more than usual)"
            loading="lazy"
        />
    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="../linkedin-has-become-a-piece-of-garbage-even-more-than-usual/index.html">
            <header class="post-card-header">
                <h2 class="post-card-title">LinkedIn Has Become a Pile of Garbage (even more than usual)</h2>
            </header>
            <section class="post-card-excerpt">
                <p>Online forums, especially Hacker News and Reddit, are very hostile to LinkedIn. Everyone makes fun of the self-promotion and silliness that goes there. There are complaints the site is unusable, which I didn&#39;t agree with until now.

I&#39;ve had an account there for a few years.</p>
            </section>
        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
                    <a href="../../author/Shantnu/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../../content/images/size/w100/2021/08/shantnu-foto-small-1.jpg" alt="Shantnu Tiwari" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../../author/Shantnu/index.html">Shantnu Tiwari</a></span>
                <span class="post-card-byline-date"><time datetime="2024-01-29">Jan 29, 2024</time> <span class="bull">&bull;</span> 4 min read</span>
            </div>
        </footer>

    </div>

</article>

    </div>
</aside>


    </main>

    <footer class="site-footer outer">
        <div class="inner">
            <section class="copyright"><a href="../../home/index.html">Python for Engineers</a> &copy; 2025</section>
            <nav class="site-footer-nav">
                
            </nav>
            

        </div>
    </footer>

</div>


<script
    src="/assets/js/jquery-3.5.1.min.js"
    integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous">
</script>
<script src="../../assets/built/casper.js"></script>
<script>
$(document).ready(function () {
    // Mobile Menu Trigger
    $('.gh-burger').click(function () {
        $('body').toggleClass('gh-head-open');
    });
    // FitVids - Makes video embeds responsive
    $(".gh-content").fitVids();
});
</script>

<script src="/assets/js/prism.min.js" integrity="sha512-axJX7DJduStuBB8ePC8ryGzacZPr3rdLaIDZitiEgWWk2gsXxEFlm4UW0iNzj2h3wp5mOylgHAzBzM4nRSvTZA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>



<script src="/assets/js/prism-toolbar.min.js" integrity="sha512-YrvgEHAi5/3o2OT+/vh1z19oJXk/Kk0qdVKbjEFl9VRmcLTaWRYzVziZCvoGpJ2TrnV7rB8pnJcz1ioVJjgw2A==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

</body>
</html>
